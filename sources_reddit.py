"""
–ü—Ä–æ—Å—Ç–æ–π –º–æ–¥—É–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ–º–æ–≤ —Å Reddit (r/memes) –∏ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö
–≤ –±–∞–∑–µ –º–µ–º–æ–≤ Telegram-–∫–∞–Ω–∞–ª–∞.

–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–±–ª–∏—á–Ω—ã–π JSON-—ç–Ω–¥–ø–æ–∏–Ω—Ç Reddit –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
"""

from __future__ import annotations

import json
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional

import easyocr
import numpy as np
import requests
from PIL import Image

from config import load_app_config
from embeddings import search_similar_by_image
from taste_model import get_taste_model, SIMILARITY_THRESHOLD


@dataclass
class RedditMemeCandidate:
    reddit_id: str
    title: str
    image_url: str
    best_score: float
    best_match: dict


CANDIDATES_FILE = Path("data/reddit_candidates.json")


def _fetch_reddit_json(subreddit: str, limit: int) -> dict:
    url = f"https://www.reddit.com/r/{subreddit}/top.json"
    params = {"limit": limit, "t": "day"}
    headers = {"User-Agent": "memes-ai-bot/0.1"}
    resp = requests.get(url, params=params, headers=headers, timeout=10)
    resp.raise_for_status()
    return resp.json()


def _extract_image_posts(data: dict) -> List[dict]:
    posts: List[dict] = []
    for child in data.get("data", {}).get("children", []):
        post = child.get("data", {})
        
        # –ü–æ–ª—É—á–∞–µ–º URL –∫–∞—Ä—Ç–∏–Ω–∫–∏
        url = post.get("url_overridden_by_dest") or post.get("url")
        if not url:
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞ (–ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏–ª–∏ –¥–æ–º–µ–Ω—É)
        url_lower = url.lower()
        is_image = (
            any(url_lower.endswith(ext) for ext in (".jpg", ".jpeg", ".png", ".webp", ".gif"))
            or "i.redd.it" in url_lower
            or "i.imgur.com" in url_lower
            or post.get("post_hint") == "image"
        )
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∏–¥–µ–æ –∏ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã
        if post.get("post_hint") == "hosted:video":
            continue
        
        if not is_image:
            continue
        
        posts.append(
            {
                "id": post.get("id"),
                "title": post.get("title", ""),
                "url": url,
            }
        )
    return posts


def _download_image(url: str, tmp_dir: Path) -> Path | None:
    try:
        resp = requests.get(url, timeout=15)
        resp.raise_for_status()
        suffix = ".jpg"
        if ".png" in url:
            suffix = ".png"
        elif ".webp" in url:
            suffix = ".webp"
        tmp_path = tmp_dir / f"img_{abs(hash(url))}{suffix}"
        tmp_path.write_bytes(resp.content)
        return tmp_path
    except Exception as exc:  # noqa: BLE001
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {exc}")
        return None


def _extract_text_from_image(image_path: Path) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é OCR.
    """
    try:
        reader = easyocr.Reader(['ru', 'en'], gpu=False, verbose=False)
        image = Image.open(image_path).convert("RGB")
        ocr_result = reader.readtext(np.array(image), detail=0)
        return " ".join(ocr_result).strip()
    except Exception:  # noqa: BLE001
        return ""


def fetch_and_match_reddit_memes(
    limit: int = 50,
    use_taste_model: bool = True,
    taste_threshold: float = SIMILARITY_THRESHOLD,
) -> List[RedditMemeCandidate]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ–º—ã –∏–∑ r/memes, –∏—â–µ—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∞–º—ã–µ –ø–æ—Ö–æ–∂–∏–µ –º–µ–º—ã
    –≤ –±–∞–∑–µ Telegram-–∫–∞–Ω–∞–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ JSON.
    
    Args:
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        use_taste_model: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤–∫—É—Å–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        taste_threshold: –ü–æ—Ä–æ–≥ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ –≤–∫—É—Å–∞
    """
    cfg = load_app_config()
    subreddit = cfg.reddit.subreddit

    print(f"–ó–∞–ø—Ä–∞—à–∏–≤–∞—é Reddit r/{subreddit} (–ª–∏–º–∏—Ç: {limit})...")
    try:
        raw = _fetch_reddit_json(subreddit, limit=limit)
    except Exception as exc:  # noqa: BLE001
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Reddit: {exc}")
        return []
    
    posts = _extract_image_posts(raw)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(posts)} –ø–æ—Å—Ç–æ–≤ —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏")
    if not posts:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ—Å—Ç–æ–≤ Reddit.")
        return []
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤–∫—É—Å–∞, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    taste_model = None
    if use_taste_model:
        try:
            taste_model = get_taste_model()
            if taste_model.taste_vector is None:
                print("‚ö†Ô∏è  –í–µ–∫—Ç–æ—Ä –≤–∫—É—Å–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤–∫—É—Å—É –æ—Ç–∫–ª—é—á–µ–Ω–∞")
                use_taste_model = False
        except Exception as exc:  # noqa: BLE001
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –≤–∫—É—Å–∞: {exc}, –ø—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –Ω–µ—ë")
            use_taste_model = False

    candidates: List[RedditMemeCandidate] = []

    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(posts)} –ø–æ—Å—Ç–æ–≤...")
    with tempfile.TemporaryDirectory() as tmp:
        tmp_dir = Path(tmp)
        for idx, post in enumerate(posts, 1):
            print(f"[{idx}/{len(posts)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {post['title'][:50]}...")
            img_path = _download_image(post["url"], tmp_dir)
            if not img_path:
                print(f"  ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É")
                continue

            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            image = Image.open(img_path).convert("RGB")
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–æ–¥–µ–ª–∏ –≤–∫—É—Å–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
            if use_taste_model and taste_model:
                try:
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (OCR)
                    ocr_text = _extract_text_from_image(img_path)
                    if not ocr_text:
                        ocr_text = post.get("title", "")
                    
                    # –û—Ü–µ–Ω–∫–∞ –º–µ–º–∞ –º–æ–¥–µ–ª—å—é –≤–∫—É—Å–∞
                    embedding, similarity, is_similar = taste_model.evaluate_meme(
                        image, ocr_text, taste_threshold
                    )
                    
                    if not is_similar:
                        print(
                            f"  üöΩ –ü–†–û–ü–£–©–ï–ù –ø–æ –≤–∫—É—Å—É (similarity: {similarity:.4f} < {taste_threshold})"
                        )
                        continue
                    else:
                        print(
                            f"  ‚úÖ –û–î–û–ë–†–ï–ù–û –ø–æ –≤–∫—É—Å—É (similarity: {similarity:.4f})"
                        )
                except Exception as exc:  # noqa: BLE001
                    print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –≤–∫—É—Å–∞: {exc}, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                    continue

            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –º–µ–º–æ–≤ –≤ –±–∞–∑–µ –∫–∞–Ω–∞–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω)
            best_score = similarity if use_taste_model else 0.0
            best_meta = {}
            
            try:
                matches = search_similar_by_image(img_path, top_k=3)
                if matches:
                    best_score, best_meta = matches[0]
                    print(f"  ‚úì –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö –º–µ–º–æ–≤ –≤ –±–∞–∑–µ, –ª—É—á—à–∏–π score: {best_score:.3f}")
                else:
                    print(f"  ‚ÑπÔ∏è  –ò–Ω–¥–µ–∫—Å –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –≤–∫—É—Å–∞")
            except FileNotFoundError:
                # –ò–Ω–¥–µ–∫—Å –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –≤–∫—É—Å–∞
                print(f"  ‚ÑπÔ∏è  –ò–Ω–¥–µ–∫—Å –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –≤–∫—É—Å–∞")
            except Exception as exc:  # noqa: BLE001
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ: {exc}, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
            
            candidate = RedditMemeCandidate(
                reddit_id=post["id"],
                title=post["title"],
                image_url=post["url"],
                best_score=best_score,
                best_match=best_meta,
            )
            candidates.append(candidate)

    CANDIDATES_FILE.parent.mkdir(parents=True, exist_ok=True)
    data = [
        {
            "reddit_id": c.reddit_id,
            "title": c.title,
            "image_url": c.image_url,
            "best_score": c.best_score,
            "best_match": c.best_match,
        }
        for c in candidates
    ]
    CANDIDATES_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), "utf-8")

    print(
        f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ {CANDIDATES_FILE}. "
        "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –∫–∞–Ω–∞–ª."
    )

    return candidates


if __name__ == "__main__":
    fetch_and_match_reddit_memes()


